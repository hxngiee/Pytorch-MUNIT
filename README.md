# MUNIT                                               
Multimodal Unsupervised Image-to-Image Translation
        
## Train
    $ python main.py --mode train \
                     --scope [scope name] \
                     --name_data [data name] \
                     --dir_data [data directory] \
                     --dir_log [log directory] \
                     --dir_checkpoint [checkpoint directory] \
                     --ny_load [size y of center crop] \
                     --nx_load [size x of center crop] \
                     --selected_attrs [attributes type]
                     --gpu_ids [gpu id; '-1': no gpu, '0, 1, ..., N-1': gpus]  
---
    $ python main.py --mode train \
                     --scope stargan \
                     --name_data celeba \
                     --dir_data ./datasets \
                     --dir_log ./log \
                     --dir_checkpoint ./checkpoint \
                     --ny_load 178 \
                     --nx_load 178 \
                     --selected_attrs Black_Hair Blond_Hair Brown_Hair Male Young
                     --gpu_ids 0                                  
---
    $ python main.py --mode train \
                     --scope stargan \
                     --name_data rafd \
                     --dir_data ./datasets \
                     --dir_log ./log \
                     --dir_checkpoint ./checkpoint \
                     --ny_load 640 \
                     --nx_load 640 \
                     --selected_attrs angry contemptuous disgusted fearful happy neutral sad surprised
                     --gpu_ids 0

* Set **[scope name]** uniquely.
* Hyperparameters were written to **arg.txt** under the **[log directory]**.
* To understand hierarchy of directories based on their arguments, see **directories structure** below. 


## Test
    $ python main.py --mode test \
                     --scope [scope name] \
                     --name_data [data name] \
                     --dir_data [data directory] \
                     --dir_log [log directory] \
                     --dir_checkpoint [checkpoint directory] \
                     --ny_load [size y of center crop] \
                     --nx_load [size x of center crop] \
                     --selected_attrs [attributes type] \
                     --dir_result [result directory]       
                     --gpu_ids [gpu id; '-1': no gpu, '0, 1, ..., N-1': gpus]              
---
    $ python main.py --mode test \
                     --scope pix2pix \
                     --name_data celeba \
                     --dir_data ./datasets \
                     --dir_log ./log \
                     --dir_checkpoint ./checkpoints \
                     --ny_load 178 \
                     --nx_load 178 \
                     --selected_attrs Black_Hair Blond_Hair Brown_Hair Male Young \
                     --dir_result ./results
                     --gpu_ids 0
---
    $ python main.py --mode test \
                     --scope pix2pix \
                     --name_data rafd \
                     --dir_data ./datasets \
                     --dir_log ./log \
                     --dir_checkpoint ./checkpoints \
                     --ny_load 640 \
                     --nx_load 640 \
                     --selected_attrs angry contemptuous disgusted fearful happy neutral sad surprised \
                     --dir_result ./results
                     --gpu_ids 0
                     
* To test using trained network, set **[scope name]** defined in the **train** phase.
* Generated images are saved in the **images** subfolder along with **[result directory]** folder.
* **index.html** is also generated to display the generated images.  


## Tensorboard
    $ tensorboard --logdir [log directory]/[scope name]/[data name] \
                  --port [(optional) 4 digit port number]
---
    $ tensorboard --logdir ./log/cyclegan/celeba \
                  --port 6006
---
    $ tensorboard --logdir ./log/cyclegan/rafd \
                  --port 6006
                                    
After the above comment executes, go **http://localhost:6006**

* You can change **[(optional) 4 digit port number]**.
* Default 4 digit port number is **6006**.


## Results
![alt text](./img/generated_images_celeba.png "Generated Images by StarGAN")

    1st row: input
    2nd row: black hair (domain A)
    3rd row: blond hair (domain B)
    4th row: brown hair (domain C)
    5th row: male (domain D)
    6th row: young (domain E)

* The results were generated by a network trained with **celeba** dataset during **16 epochs**.
* After the Test phase runs, execute **display_result.py** to display the figure.

![alt text](./img/generated_images_rafd.png "Generated Images by StarGAN")

    1st row: input
    2nd row: angry (domain A)
    3rd row: contemptuous (domain B)
    4th row: disgusted (domain C)
    5th row: fearful (domain D)
    6th row: happy (domain E)
    7th row: neutral (domain F)
    8th row: sad (domain G)
    9th row: surprised (domain H)
    
* The results were generated by a network trained with **rafd** dataset during **140 epochs**.
* After the Test phase runs, execute **display_result.py** to display the figure.
